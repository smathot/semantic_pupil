How are you able to understand the words that compose this sentence?

Embodied theories of language hold that you understand words--at least those that refer to concrete actions or objects--by mentally simulating what you can do with their referents, and what these referents look, smell, and feel like. For example, according to embodied language, when you read the word 'keyboard', you mentally simulate a typing action; and when you read the word 'sun', you simulate the perception of a bright ball of fire in the sky. Strongly embodied views of language hold that such simulations are necessary for comprehension; that is, to understand what 'sun' means, you need a sensory representation of what it looks like [@GlenberGallese2012;@Pulvermüller2013]. Weakly embodied views of language hold that simulations may facilitate language comprehension, but are not strictly necessary; that is, mentally picturing the sun may help you to read 'sun', but you could understand 'sun' even without any sensory representation of it, by relying on a symbolic system [@Zwaan2014;@MahonCaramazza2008;@BednyCaramazza2011;@Meteyard2012].

Most support for embodied language comes from two general approaches: behavioral studies that look at compatibility effects between word meaning and perception (or action) [@Meteyard2008;@Meteyard2007;@Kaschak2005;@Zwaan2004;@Aravena2012]; and neuroimaging studies that compare brain activity during word reading with brain activity during perception (or action) [@Hauk2004;@Revill2008;@Vigliocco2006]. A compelling example of a behavioral compatibility effect was reported by Meteyard and colleagues [@Meteyard2008], who found that upward/ downward visual motion affects comprehension speed of words with an upward/ downward meaning [see also @Kaschak2005;@Meteyard2007]; that is, participants decided more quickly that 'fall' was a real word (as opposed to a nonword) when they simultaneously saw downward-moving dots. From this, Meteyard and colleagues concluded that understanding downward-conveying words relies, at least in part, on the same brain areas as perception of downward motion. This conclusion is, on the surface, supported by neuroimaging studies that show overlap in the brain areas that are active during both reading of words associated with motion, and perception of motion [@Revill2008].

This study and many others clearly show that language interacts with perception and action. But they do not necessarily support a strongly embodied view of language, because they can also be explained in a weakly embodied view by assuming that neural activation spreads between connected areas [@MahonCaramazza2008;@BednyCaramazza2011]. According to a spreading-activation account, the results of Meteyard and colleagues [@Meteyard2008] can be explained as follows: One brain area is involved in perceiving downward motion, while another is involved in processing words like 'fall'. These two areas are connected, and activation from one area spreads to the other; this explains why perceiving downward motion facilitates comprehension of downward-conveying words. But, in this view, the brain areas that are involved in perception and language are nevertheless distinct, and have a clear division of labor.

As pointed out in recent leading reviews [@MahonCaramazza2008;@Zwaan2014], researchers generally agree that language is neither fully embodied nor fully disembodied; but they hold a wide variety of intermediate views, all of which are consistent with currently available evidence. To progress beyond this point, new methods are needed to address specific, well-defined questions about how language is embodied. Here we present one such method, based on the pupillary light response: the constriction (shrinkage) of the eye's pupils to brightness, and dilation (expansion) of the pupils to darkness.

The pupillary light response was traditionally believed to be a low-level reflex to light; however, recent studies have shown that the light response is sensitive to high-level cognition [@Mathôt2015CurrDir;@Binda2014Trends]. For example, the pupil constricts when you covertly (without looking at it) attend to a bright, compared to a dark, object [@Mathôt2013Plos;@Binda2013Bright;@Naber2013Track]. Similarly, the pupil constricts when you imagine a bright object [@Laeng2014Imaginary], or when a bright object reaches awareness in a binocular rivalry paradigm [@Naber2011]. These phenomena are often explained in terms of top-down modulation of visual brain areas [@Wang2012Micro;@Mathôt2014]; that is, the pupil constricts when you covertly attend to a bright object, because attention enhances the representation of the bright object throughout visual cortex [@Kastner1998].

This reasoning can be naturally extended to embodied language: If word comprehension activates visual cortex (i.e. creates sensory representations), then understanding words that convey a sense of brightness or darkness should trigger pupillary responses--just like attending to [@Mathôt2013Plos] or imagining [@Laeng2014Imaginary] bright or dark objects. Phrased differently, if brightness-conveying words trigger a pupillary constriction relative to darkness-conveying words, this would support the view that word comprehension affects sensory brain areas, and can even trigger physiological (pupillary) responses.
