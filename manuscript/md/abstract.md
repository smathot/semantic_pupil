A strongly embodied view of language holds that, to understand a word, you must simulate associated sensory input (e.g. simulate perception of brightness to understand 'lamp'), and prepare associated actions (e.g. prepare finger movements to understand 'typing'). To test this, we measured pupillary responses to single words that conveyed a sense of brightness (e.g. 'day') or darkness (e.g. 'night'), or were luminance-neutral (e.g. 'house'). Crucially, we found that the pupil was largest for darkness-conveying words, intermediate for neutral words, and smallest for brightness-conveying words; however, this semantic pupillary response peaked long after participants had already understood and responded to the words. These findings suggest that word comprehension activates sensory representations, and even triggers physiological (pupillary) responses, but that this occurs too late to be a necessary part of the comprehension process itself. Instead, we suggest that pupillary responses to darkness- and brightness-conveying words--and perhaps embodied language in general--may reflect preparation for the immediate future: When you read the word 'lamp', you automatically prepare to look at a lamp, and prepare to read more brightness-related words; this may cause your pupils to constrict in anticipation.
