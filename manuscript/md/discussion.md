Here we report that the eye's pupils constrict after reading or listening to brightness-conveying words (e.g. 'sun') compared to darkness-conveying words (e.g. 'night'). This effect arises slowly and gradually, and, in our experiments, peaked between 1 and 2 s after word onset.

Our findings have important implications for theories of embodied language. Our starting premise is that an indirect (i.e. without direct visual stimulation) pupillary light response reflects sensory representations that are similar to those that arise during perception [@Laeng2014Imaginary] and involve visual brain areas [@Mathôt2014]. Our findings therefore suggest that word comprehension can induce activity in visual brain areas, and even trigger involuntary (pupillary) movement, in a way that corresponds to the word's meaning. This finding is consistent with previous behavioral studies that have shown that word meaning can modulate actions [e.g. @Aravena2012;@GlenbergKaschak2002]. However, in previous studies, actions were not triggered by word meaning per se, but imposed by the task and voluntarily performed by the participants [e.g. @Aravena2012;@GlenbergKaschak2002;@ZwaanTaylor2006]. Our findings extend these studies by showing that word meaning is by itself sufficient to trigger a movement that is not imposed by the task, and that is largely beyond voluntary control ++[see also @SpiveyGeng2001, who showed spontaneous eye movements during mental imagery]. This is in line with an embodied view of language, which holds that language processing involves sensory and motor areas of the brain, and automatically triggers simulations of perception and action [@Pulvermüller2013;@GlenberGallese2012].++

Is pupillary constriction necessary to understand words that convey a sense of brightness--as a strongly embodied view of language would say? Or is pupillary constriction merely a non-functional by-product of reading brightness-conveying words--as a weakly embodied view would say? Although our results do not speak directly to this question, we see at least two ++possible++ functional roles for embodiment in language.

First, we should note that the semantic pupillary effect occurs late, and in the visual experiment peaked even only about a second after participants had processed the word's meaning and responded to it. Therefore, it is unlikely that the pupillary movement itself played a functional role in word comprehension. However, the sensory and motor simulations that gave rise to this movement may well have been part of the comprehension process. On its own, a simulation of brightness is insufficient to identify the concept 'sun'--many things are bright. But a simulation of brightness, combined with a simulation of upwardness and that of a pleasant warm feeling on the skin, already goes some way to uniquely identifying 'sun.' In this sense, the combination of many different sensory and motor simulations, including the simulation of brightness, may be functionally involved in word comprehension and, later in time, have triggered the pupillary responses that we observed in our experiments.

Second, embodied language may play a role in preparation. For example, when you hear the name of an object that is in your field of view, you are likely to look at it [@Cooper1974]. Therefore, the pupillary constriction that is triggered by reading the word 'lamp' may reflect preparation for looking at a lamp [@Mathôt2015EyePrep]. In this view, sensory and motor representations that arise during word comprehension are not (only) part of the comprehension process, but reflect preparation for perceptions and actions that are likely to occur in the immediate future.

In summary, we have shown that the pupil constricts when reading or listening to brightness- compared to darkness-conveying words. This suggests that word comprehension is by itself sufficient to activate sensory and motor representations, and can even trigger involuntary (pupillary) movement.
